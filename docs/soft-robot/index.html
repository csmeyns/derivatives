<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Skip to main content Advertisement SpringerLink Search Log in Open Access Published: 07 August 2021 Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?
Kazuko Obayashi123, Naonori Kodate34567 & Shigeru Masuyama 38
Accepted: 19 July 2021 © The Author(s) 2021
International Journal of Social Robotics (2021) Cite this article ✉︎ Naonori Kodate naonori.kodate@ucd.ie"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?"><meta property="og:description" content="Skip to main content Advertisement SpringerLink Search Log in Open Access Published: 07 August 2021 Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?
Kazuko Obayashi123, Naonori Kodate34567 & Shigeru Masuyama 38
Accepted: 19 July 2021 © The Author(s) 2021
International Journal of Social Robotics (2021) Cite this article ✉︎ Naonori Kodate naonori.kodate@ucd.ie"><meta property="og:type" content="article"><meta property="og:url" content="https://csmeyns.github.io/derivatives/docs/soft-robot/"><meta property="article:section" content="docs"><title>Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People? | Derivatives</title><link rel=manifest href=/derivatives/manifest.json><link rel=icon href=/derivatives/favicon.png type=image/x-icon><link rel=stylesheet href=/derivatives/book.min.1a6fac2df464e68d664cb846d822c678cd622692d6fae24ee18901a08bfc8eb6.css integrity="sha256-Gm+sLfRk5o1mTLhG2CLGeM1iJpLW+uJO4YkBoIv8jrY=" crossorigin=anonymous><script defer src=/derivatives/flexsearch.min.js></script>
<script defer src=/derivatives/en.search.min.9438fa02f35523850c449d39391172a295ab3938425ff8d6b54944fc5abf6077.js integrity="sha256-lDj6AvNVI4UMRJ05ORFyopWrOThCX/jWtUlE/Fq/YHc=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/derivatives/><span>Derivatives</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=https://csmeyns.github.io/derivatives/docs/readme/>README</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/architecture-human-orc/>Architecture of the Human Origin Recognition Complex*</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/amyloid-%CE%B2/>Origins of amyloid-β</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/arsenic/>Effects of arsenic and heavy metals on metabolic pathways in cells of human origin: Similarities and differences</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/back-to-future/>Back to the future: origins and directions of the “Agile Manifesto” – views of the originators</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/biopolymers/>Folding, Assembly, and Persistence: The Essential Nature and Origins of Biopolymers</a></li><li><input type=checkbox id=section-4e626a39f813bdfb0b0f11621a8d97e6 class=toggle>
<label for=section-4e626a39f813bdfb0b0f11621a8d97e6 class="flex justify-between"><a href=https://csmeyns.github.io/derivatives/docs/cc-by/>CC-BY</a></label><ul><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-2-summary/>Creative Commons License Deed Attribution 2.0 Generic (CC BY 2.0)</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-2/>Creative Commons Legal Code Attribution 2.0</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-3-summary/>Creative Commons License Deed Attribution 3.0 Unported (CC BY 3.0)</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-3/>Creative Commons Attribution 3.0 Unported</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-4-summary/>Creative Commons License Deed Attribution 4.0 International (CC BY 4.0)</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-4-de/>Creative Commons Konzessionsurkunde Namensnennung 4.0 International (CC BY 4.0)</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/cc-by/cc-by-4/>Creative Commons Legal Code Attribution 4.0 International</a></li></ul></li><li><a href=https://csmeyns.github.io/derivatives/docs/charon-smooth-plains/>The nature and origin of Charon's smooth plains</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/chinese-word-cell/>Origin of the Chinese word for “cell”: an unusual but wonderful idea of a mathematician</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/city-origins/>City origins</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/counterfeit-versus-original/>Counterfeit versus original patronage: Do emotional brand attachment, brand involvement, and past experience matter?</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/creatine/>ON THE ORIGIN OF CREATINE</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/detecting-moisture/>Detecting the origins of moisture over Southeast China: Seasonal variation and heavy Rainfall</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/differentiation-spirits/>Differentiation Between Spirits According to Their Botanical Origin</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/food-taboos/>Food taboos: their origins and purposes</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/ganges/>Ganges: special at its origin</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/given-that-detailed/>Given that the detailed original criteria for deliberate practice have not changed, could the understanding of this complex concept have improved over time? A response to Macnamara and Hambrick (2020)</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/hanwoo-cattle/>Hanwoo cattle: origin, domestication, breeding strategies and genomic selection</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/hoarding/>The developmental origins of hoarding disorder in adolescence: a longitudinal clinical interview study following an epidemiological survey</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/how-to-write/>How to write an original article for the *Journal of Orthopaedics and Traumatology*</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/in-out-qinghai-tibet-plateau/>“Into and Out of” the Qinghai-Tibet Plateau and the Himalayas: Centers of origin and diversification across five clades of Eurasian montane and alpine passerine birds</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/interview-patrick-o-brown/>An interview with Patrick O Brown on the origins and future of open access</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/manipulated-photos/>Can people identify original and manipulated photos of real-world scenes?</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/neighborhood-spam/>Neighborhoods and bands: an analysis of the origins of spam</a></li><li><input type=checkbox id=section-18bd70f4fad61eb2742d114842aa84cf class=toggle>
<label for=section-18bd70f4fad61eb2742d114842aa84cf class="flex justify-between"><a href=https://csmeyns.github.io/derivatives/docs/letters/>Letters</a></label><ul><li><a href=https://csmeyns.github.io/derivatives/docs/letters/non-neanderthal/>Non-Neanderthal Origin of the HLA-DPB1*0401</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/letters/reply-to-ding/>Reply to Ding et al.: Non-Neanderthal Origin of the HLA-DPB1*0401</a></li></ul></li><li><a href=https://csmeyns.github.io/derivatives/docs/origin-of-the-ectopic-beat/>What is the origin of the ectopic beat?</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/origins/>Origins</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/patient-safety/>The 5th anniversary of “Patient Safety in Surgery” – from the Journal’s origin to its future vision</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/rendang/>Tracing the origins of rendang and its development</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/soft-robot/ class=active>Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/softwaretest-originaldaten/>Softwaretest mit Originaldaten Eine Analyse aus Sicht des Datenschutzes</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/spectacular-submarine/>Origin of spectacular fields of submarine sediment waves around volcanic islands</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/urban-conservation/>Urban Conservation Through Chinese Local Original Architecture: The Preservation and Renovation of Zhongshan Road in Hangzhou</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/vertebrate-gills/>The Origin of Vertebrate Gills</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/volcanic-origin-1741/>Volcanic origin of the 1741 Oshima-Oshima tsunami in the Japan Sea</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/what-is-morita-therapy/>What is Morita Therapy? The Nature, Origins, and Cross-Cultural Application of a Unique Japanese Psychotherapy</a></li><li><a href=https://csmeyns.github.io/derivatives/docs/wildcat-reappearance/>Revealing the origin of wildcat reappearance after presumed long-term absence</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/derivatives/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?</strong>
<label for=toc-control><img src=/derivatives/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#research-settings-robot-design-and-development-process>Research Settings, Robot Design and Development Process</a><ul><li><a href=#settings-and-participants>Settings and Participants</a></li><li><a href=#user-centered-design-and-development-in-a-nursing-home>User-Centered Design and Development in a Nursing Home</a></li><li><a href=#development-of-conversation-scenarios>Development of Conversation Scenarios</a></li></ul></li><li><a href=#evaluation-of-verbal-and-non-verbal-mon-chan>Evaluation of Verbal and Non-verbal Mon-chan</a><ul><li><a href=#evaluation-methods-and-procedures>Evaluation Methods and Procedures</a></li><li><a href=#changes-of-qol-assessed-by-interrai>Changes of QoL Assessed by interRAI</a></li><li><a href=#short-term-emotional-changes-captured-by-vc-ioe>Short-Term Emotional Changes Captured by VC-IOE</a></li></ul></li><li><a href=#discussion>Discussion</a></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#references>References</a></li><li><a href=#acknowledgements>Acknowledgements</a></li><li><a href=#author-information>Author information</a><ul><li><a href=#affiliations>Affiliations</a></li><li><a href=#corresponding-author>Corresponding author</a></li></ul></li><li><a href=#ethics-declarations>Ethics declarations</a><ul><li><a href=#conflict-of-interest>Conflict of interest</a></li></ul></li><li><a href=#additional-information>Additional information</a><ul><li><a href=#publishers-note>Publisher&rsquo;s Note</a></li></ul></li><li><a href=#rights-and-permissions>Rights and permissions</a></li><li><a href=#reprints-and-permissions>Reprints and Permissions</a><ul><li><a href=#about-this-article>About this article</a></li><li><a href=#cite-this-article>Cite this article</a></li><li><a href=#share-this-article>Share this article</a></li><li><a href=#get-shareable-link>Get shareable link</a></li></ul></li><li><a href=#keywords>Keywords</a></li><li><a href=#advertisement>Advertisement</a></li></ul></nav></aside></header><article class=markdown><h1><a href=/derivatives/docs/soft-robot/>Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?</a></h1><h2>Kazuko Obayashi, Naonori Kodate & Shigeru Masuyama</h2><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Skip to main content</br>Advertisement</br>SpringerLink</br><p>Search</br>Log in</br>Open Access</br>Published: 07 August 2021</br>Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?</p></div><p>Kazuko Obayashi<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, Naonori Kodate<sup id=fnref1:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup><sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup><sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup> & Shigeru Masuyama <sup id=fnref2:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup><sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup></p><p>Accepted: 19 July 2021
© The Author(s) 2021</p><p>International Journal of Social Robotics (2021)
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Cite this article</div></p><p>✉︎ Naonori Kodate <a href=mailto:naonori.kodate@ucd.ie>naonori.kodate@ucd.ie</a></p><p>Published online: 07 August 2021 Springer</p><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">373 Accesses
9 Altmetric
Metrics details</div><h2 id=abstract>Abstract
<a class=anchor href=#abstract>#</a></h2><p>It has been reported that robotics-aided care can contribute to enhancing older people’s social participation and quality of life in nursing homes, while simultaneously reducing the burden on care professionals at nighttime. Due to increasing demand for social care and the relative workforce shortage, it is likely that a greater number and variety of robots will be introduced and implemented in the future. While the benefits of applying robots and assistive technologies are recognized, the current limitations and weaknesses have also been identified. One of these is the difficulty associated with a user-centered design, involving older adults with impaired cognitive and sensory abilities in nursing homes. In order to overcome this challenge, a project was carried out to develop a soft and compact bedside communication robot with an input/output device, connected to existing technologies (e.g. monitoring camera, biological sensor). Drawing on the principle of <em>gemba</em> (deference to frontline professionals’ experience, expertise and skills), users’ feedback was reflected in the iterative steps of robot development. The original soft and communicative robot was introduced and its effectiveness was tested by measuring older people’s reactions and changes in their behaviors and engagement levels. The article reports the development process and results of a small-scale evaluation study, comparing the impact of this original soft-type robot with and without its communicative functions. The human–robot interactions were captured on video, and the analysis revealed that while communicative robots reduced the psychosocial burden on older adults, positive emotional, verbal, visual and behavioral engagement was generated with the help of the non-verbal plush toy.</p><p><strong>Keywords</strong> Socially assistive robot · Eldercare · Communication · User-centered design · Human–robot interaction · Technology assessment</p><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><p>The global population aged 60 years or over reached 962 million in 2017, more than twice the population reported in 1980. The pace of aging is accelerating across the world and the number of older people is projected to reach more than 2 billion by 2050. Accordingly, the number of people affected by dementia has been on the increase, and the current number (approximately 47 million, as of 2018) is estimated to reach 75 million by 2030 [1]. The World Health Organization (WHO) published a report in 2015 [2], which outlined a framework for action to foster healthy aging based on the new concept of functional ability. In order to support healthy aging and meet the increasing demand (e.g. shortage of workforce), manufacturers and policymakers across the globe are emphasizing development and production of more efficient and effective assistive technologies (ATs) including care robots. Furthermore, the recent global pandemic has affected the lives of older people particularly harshly, and reinforced the view that building capacity in health systems by utilizing technologies should be one of the public policy priorities.</p><p>Research shows that older people’s acceptance of care robots can be affected by the robot’s appearance, materials and functionalities [3, 4]. It is suggested that even younger users prefer soft and cuddly robots over those with a cold, hard shell [5]. However, thus far usability, user-friendliness and outcome evaluation of these care robots have rarely been tested from the end-users’ point of view [6]. Moreover, in long-term care settings, it is not uncommon that some older users cannot verbally express their needs. To address these weaknesses, a user-centered design has been introduced for socially assistive robots (SARs) and promoted in some countries [7,8,9]. Globally, the Responsible Research and Innovation (RRI) framework has been proposed and used [9]. In Japan in recent years, users’ needs have been explored and identified by several key players such as the Japanese Association of Occupational Therapists and the Association of Technical Aids (established as a public interest incorporated foundation in 1987) [10]. These efforts are primarily targeted at understanding the ’needs’ of users (care recipients and caregivers) so that manufacturers, funding bodies and care providers can develop their ’seeds’ and deliver technological aids. Despite these efforts, user involvement is still a rare occurrence. This is partly because hurdles to a participatory approach remain high when the users include older adults with impaired ability. Under such circumstances, caregivers’ inputs as proxy for older people’s voice become highly important and valuable, although it should be acknowledged that this is not the same as public and patient involvement.</p><p>In the Japanese context, with the concept of <em>gemba</em> (‘actual site/field’ in Japanese), professional expertise, experience and skills have been highly valued. Originating in the manufacturing industry, gemba has been adopted in healthcare, alongside the more widely-known concept of <em>kaizen</em> (‘improvement’ in Japanese), even outside Japan [10, 11]. Guided by this bottom-up process and principle, frontline care professionals proactively identified the needs of care recipients, incorporated changes into the development of SARs, and received feedback from the care recipients. We hypothesized that by making SARs more user-friendly and accessible, better outcomes and a higher quality of life would result. In order to examine this hypothesis, research was conducted to assess the impact of using such SARs on older people.</p><p>Concerning the outcome evaluation of using existing SARs, previous studies highlighted positive impacts on older people [12,13,14,15,16,17,18,19,20]. Examples from the previous studies include the positive impact of SARs on older people’s activity and social participation [4, 21] and on older adults with moderate dementia [22, 23]. When using a soft tactile robot, the non-verbal type can elicit reactions in older people with advanced dementia [22]. On the other hand, when using verbal type SARs, research indicated that other features such as input/output devices and sound volume need adjustments and improvements in order for the care system to utilize the equipment effectively [22]. Further development of soft and cuddly SARs and the evaluation of their impact on older people in residential care settings was deemed necessary to advance the science behind the effectiveness of these care robots.</p><p>Against this background, this project was launched to develop and assess a bedside communication soft robot with an input/output device, connected to a monitoring camera and biological sensor, while reflecting the needs of direct users (care professionals and care recipients). Given our previous research, the purpose was to design and develop a soft robot [23] that can be used both as a non-verbal and verbal companion plush toy, as well as a socially interactive communication tool. The effectiveness of the SAR produced was also tested. The article reports the development process of this robot named Mon-chan (a monster-looking doll bringing harmonious communications among users), and presents results of an evaluation study conducted in the nursing home, exploring future research agendas.</p><h2 id=research-settings-robot-design-and-development-process>Research Settings, Robot Design and Development Process
<a class=anchor href=#research-settings-robot-design-and-development-process>#</a></h2><p>The development process started from users’ perspectives (older persons and care professionals), extracting the core issues identified with the previous setup and using various assistive technologies (a monitoring camera and communication robots, in particular). The gemba principle drove this process with frontline care professionals representing the voice of care recipients, particularly those who are not physically mobile enough to reach and press the nurse call button when they need assistance.</p><h3 id=settings-and-participants>Settings and Participants
<a class=anchor href=#settings-and-participants>#</a></h3><p>In Japan, there are different types of care facilities. The facility selected for this study is a special nursing home for older people. There are 30 residents (25 female, 5 male; 86.8±6.8
86.8 ±6.8 years old). From the group of care professionals, 4 senior staff members in the nursing home participated in the design process of the robot and the data collection. The years of experience vary from 7 to 20 (11 on average) years. In order to ensure objectivity, the analysis was conducted by three researchers who were not involved in the collection of data. Ethics approval was granted by the Social Welfare Corporation Tokyo Sacramental Ethics Committee (TS 2019- 004). Consent was sought from each participant and their family. The research was conducted between October 2019 and March 2020.</p><h3 id=user-centered-design-and-development-in-a-nursing-home>User-Centered Design and Development in a Nursing Home
<a class=anchor href=#user-centered-design-and-development-in-a-nursing-home>#</a></h3><p>Most conventional communication robots have a hard shell which gives a cold impression for both residents and staff. As suggested by previous research, the sense of touch is a critical element for older adults’ engagement with social robots [5, 6, 16, 24, 25, 26]. The hard shell also meant that physical deployment is highly restricted in the context of nursing homes, as it requires a solid surface, such as a bedside table. As the physical distance between SARs and care recipients was not adjustable, residents had difficulty hearing and understanding what SARs were saying. From the staff’s point of view, there has always been an issue of having to go to the room to see what has happened to a resident each time a nurse call button was pressed, particularly during nighttime. It was hoped that a work system, aided by ATs, could send the warning signs or visual information wherever care professionals are, so that they can arrive in time before problems such as falls occur. In the past, there were some weaknesses in the ICT environment issues, such as time lag via the Cloud and malfunctions.</p><p><img src=/img/soft-robot_fig1.png alt="Overall concept and SAR development"></p><figcaption><p><strong>Fig. 1</strong>
figure1
Overall concept and SAR development</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><p>User-centered design dictates that priority should be placed on development of a communication robot that meets their needs. The overall concept therefore was to create a soft shell SAR with an input/output device which is connected to the nurse call button and the monitoring camera. Figure 1 describes the overall concept and the development process.</p><p>The system requirements include the capability of (i) remotely monitoring and sending signals to care staff when help is needed; (ii) watching over older people around the bed; and (iii) providing older people with a voice-controlled alternative method to a nurse call; and (iv) small, compact and audible robot with soft and warm appearance, which can be securely hung over the bed-rail without hindering its vertical movement.</p><p>The first two requirements ((i) and (ii)) were fulfilled by the existing devices, which monitor the person with a bed-side infrared camera. In case of emergencies such as falls, alerts were sent to the central nursing station as well as care professionals on duty. For the third requirement (iii), a voice-controlled alternative method was considered at the beginning. However, the idea of developing and installing a two-way communication system into the robot had to be rejected for reasons of cost and time. Instead, the team decided to rely on the existing nurse call system, and this was activated when the alert was received by care staff, so that the care recipient in need of help could communicate verbally. The main focus of this project was narrowed down to fulfil (iv).</p><p>From basic design to development of the interface design, the iterative, PDCA (plan, do, check, do, act) cycle method was applied (Fig. 2). The processes for the robot (exterior) design and internal functional design were separated, and the latter proceeded with the development of verbal communication functions (e.g. system design and scenarios for conversations) and non-verbal aspects.</p><p>Much attention was paid to the human–robot interface design, with consideration of its appearance and voice functionality. At each stage, discussions were held between manufacturers and frontline care professionals. As a result, softer plush fabrics were chosen, and the SAR made more compact, yet more stable on the bedrail using larger paws, though it was not feasible to add a variety of voice types. Table 1 shows the changes made to the design and functions of the SAR after the iterative process of consultations.</p><p><img src=/img/soft-robot_fig2.png alt="Two-stage process of developing SAR “Mon-chan” using the PDCA method"></p><figcaption><p><strong>Fig. 2</strong>
figure2
Two-stage process of developing SAR “Mon-chan” using the PDCA method</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><figcaption><p><strong>Table 1</strong> Intended design and function of SAR “Mon-chan” and end product</p></figcaption><table><thead><tr><th></th><th>Intended design and function</th><th>End product</th></tr></thead><tbody><tr><td>Design</td><td>Soft and warm; appealing appearance; compact; stable on bedrail</td><td>Plush fabrics used; smaller mouth/ ears; larger paws for ease of hanging</td></tr><tr><td>Function</td><td>Audible sound (tone and pace); flexibility in changing scenario type of voice; device protected from vibrations (e.g. substrate)</td><td>Lower pitched voice; slower pace of speech; new colored record button; individualized scenarios; substrate covered with plastic</td></tr></tbody></table><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size table</div><figcaption><p><strong>Table 2</strong> Three types of communication scenarios</p></figcaption><table><thead><tr><th>Scenario common to all individuals</th><th>Scenario unique to</th><th>Conversations activated by monitoring camera</th></tr></thead><tbody><tr><td>e.g. “Soon breakfast will be served.” (6:30 am), ‘Soon it’ll be time for physical exercise” (11 am). “Did you have a good day? Please have some good rest” (8 pm)</td><td>e.g. “Today you’ll have a bath” “Would you like to join today’s calligraphy class, starting soon?”, “Today you have an appointment with your doctor.”</td><td>e.g. “What’s happened? Would you like to go to the toilet?”, “Staff will be here in a minute, so please wait a moment.”, “How are you today?”</td></tr></tbody></table><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size table</div><h3 id=development-of-conversation-scenarios>Development of Conversation Scenarios
<a class=anchor href=#development-of-conversation-scenarios>#</a></h3><p>One of the key aspects of the SAR design was the set of conversation scenarios, which were developed based on daily care routines (see Table 2). Messages about meals, wake-up, and bedtime (the timing of wake-up and bedtime messages were set individually) was input for all residents. A conversation scenario about recreation and toileting was tailored for each person, reflecting their lifestyles and daily patterns. In addition, the team enabled the scenario to be adjusted for each person, based on previous recordings captured by the monitoring camera. This was particularly important for conversations taking place during the night, when residents wake up. When the movement of a resident in her room is detected, the signal sent from the monitoring sensor (installed in each room) instructs the SAR’s server to speak, and based on the created scenario, recorded voice and sound synthesis are transferred via the SIP server, and the SAR speaks to the resident. For example, the Mon-chan robot asks “What’s happened?” when the resident tries to get up. In response to her saying “I want to go to the toilet”, Mon-chan says “Staff will be here in a minute, so please wait a moment.”</p><p>Mon-chan was produced this way, and this communication robot (10 [cm] ×
× 7 [cm] × 5 [cm]), which looks like a stuffed animal, contains an I/O device (Table 3, Fig. 3).</p><figcaption><p><strong>Table 3</strong> Features of SAR Mon-chan</p></figcaption><table><thead><tr><th>Input/output device</th><th>A camera/monaural microphone/speaker/power over Ethernet (POE) available</th></tr></thead><tbody><tr><td>Interactions</td><td>Typed sentences converted into voices. Voices pre-programmed and personalized according to the needs of each participant</td></tr><tr><td>Features</td><td>Provides safety monitoring via infrared sensor and alert functions, connected to nursing station. Allows users to speak with a care professional through the device</td></tr></tbody></table><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size table</div><p><img src=/img/soft-robot_fig3.jpg alt="SAR “Mon-chan” and equipment inside the robot"></p><figcaption><p><strong>Fig. 3</strong>
figure3
SAR “Mon-chan” and equipment inside the robot</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><h2 id=evaluation-of-verbal-and-non-verbal-mon-chan>Evaluation of Verbal and Non-verbal Mon-chan
<a class=anchor href=#evaluation-of-verbal-and-non-verbal-mon-chan>#</a></h2><p>As previously mentioned, Mon-chan is a communication robot that has soft appearance and pleasant touch, resembling a non-verbal pet-type robot. When it is used by the bedside, it is also linked with an infrared monitoring camera and a biological sensor.</p><h3 id=evaluation-methods-and-procedures>Evaluation Methods and Procedures
<a class=anchor href=#evaluation-methods-and-procedures>#</a></h3><p>For this evaluation, we employed two methods (the interRAI and Video Coding Protocol-Incorporating Observed Emotion (VC-IOE)). Verbal Mon-chan was used at all times in each resident’s room for all participants, while Mon-chan, in both verbal and non-verbal mode, was tested when the latter method was used to observe each resident’s personal interactions with Mon-chan. The evaluation took place for 4 weeks during the months of February and March 2020. The video-recording and observation sessions were held in the fourth week. The interRAI is one of the standardized assessment instruments for those who receive care. These scales measure physical abilities (activities of daily living (ADLs)), cognitive impairment and quality of life. The assessment items are organized into sections dealing with issues such as cognitive patterns, communication and hearing patterns, and physical functionality [27,28,29]. The self-rated or assessor-rated interRAI scores can be used as proxy for older people’s Quality of Life (QoL). Prior to the introduction of Mon-chan, we collated residents’ scores for two categories (E: Mood and Behavior; F: Psychosocial well-being) [30], and compared them with those collected 4 weeks after the introduction of Mon-chan (Table 4). The higher the scores are, the larger the burden is on mood, behavior and psychosocial well-being. The results are presented below (Sect. 3.2).</p><figcaption><p><strong>Table 4</strong> Excerpt of interRAI (E: Mood and Behavior, F: Psychosocial well-being) [30],?</p></figcaption><table><thead><tr><th></th><th>SECTION E. MOOD AND BEHAVIOR</th></tr></thead><tbody><tr><td></td><td>E1. INDICATORS OF POSSIBLE DEPRESSED, ANXIOUS, OR SAD MOOD</td></tr><tr><td></td><td>Code for indicators observed in last 3 days, irrespective of the assumed cause [Note: Whenever possible, ask person] 0. Not present; 1. Present but not exhibited in last 3 days; 2. Exhibited on 1–2 of last 3 days; 3. Exhibited daily in last 3 days</td></tr><tr><td>E1a.</td><td>Made negative statements</td></tr><tr><td>E1b.</td><td>Persistent anger with self or others</td></tr><tr><td>E1c.</td><td>Expressions, including non-verbal, of what appear to be unrealistic fears</td></tr><tr><td>E1d.</td><td>Repetitive health complaints</td></tr><tr><td>E1e.</td><td>Repetitive anxious complaints/concerns (non-health-related)</td></tr><tr><td>E1f.</td><td>Sad, pained, or worried facial expressions</td></tr><tr><td>E1g.</td><td>Crying, tearfulness</td></tr><tr><td>E1h.</td><td>Recurrent statements that something terrible is about to happen</td></tr><tr><td>E1i.</td><td>Withdrawal from activities of interest</td></tr><tr><td>E1j.</td><td>Reduced social interactions</td></tr><tr><td>E1k.</td><td>Expressions, including nonverbal, of a lack of pleasure in life</td></tr><tr><td>E3.</td><td>BEHAVIOR SYMPTOMS</td></tr><tr><td></td><td>0. Not in last 3 days; 1. Not in last 3 days, but often feels that way; 2. In 1–2 of last 3 days; 3. Daily in last 3 days</td></tr><tr><td>E3a.</td><td>Wandering</td></tr><tr><td>E3b.</td><td>Verbal abuse</td></tr><tr><td>E3c.</td><td>Physical abuse</td></tr><tr><td>E3d.</td><td>Socially inappropriate/disruptive behavior</td></tr><tr><td>E3e.</td><td>Inappropriate public sexual behavior or public disrobing</td></tr><tr><td>E3f.</td><td>Resists care</td></tr><tr><td>E3g.</td><td>Absconding or at risk of absconding</td></tr><tr><td></td><td><strong>SECTION F. PSYCHOSOCIAL WELL-BEING</strong></td></tr><tr><td>F3.</td><td>CHANGE IN SOCIAL ACTIVITIES IN LAST 90 DAYS</td></tr><tr><td></td><td>0. No decline; 1. Decline, not distressed; 2. Decline, distressed</td></tr><tr><td>F4.</td><td>LENGTH OF TIME ALONE DURING THE DAY (MORNING AND AFTERNOON)</td></tr><tr><td></td><td>0. Less than 1 h; 1. 1–2 h; 2. More than 2 h but less than 8 h; 3. 8h or more</td></tr><tr><td></td><td>SECTION E. MOOD AND BEHAVIOR</td></tr><tr><td>F5.</td><td>WILLINGNESS TO INITIATE OR PARTICIPATE</td></tr><tr><td></td><td>0. Not in last 3 days; 1. Not in last 3 days, but often feels that way; 2. In 1–2 of last 3 days; 3. Daily in last 3 days</td></tr><tr><td>F5a.</td><td>At ease interacting with others</td></tr><tr><td>F5b.</td><td>At ease doing planned or structured activities</td></tr><tr><td>F5c.</td><td>Accepts invitations to most group activities</td></tr><tr><td>F5e.</td><td>Initiates interaction(s) with others</td></tr><tr><td>F5f.</td><td>Reacts positively to interactions initiated by others</td></tr><tr><td>F5g.</td><td>Adjusts easily to change in routine</td></tr><tr><td>F6.</td><td>INSTABILITY OF INTERPERSONAL RELATIONSHIP</td></tr><tr><td></td><td>0. No; 1. Yes</td></tr><tr><td>F6a.</td><td>Conflict with or repeated criticism of other care recipients</td></tr><tr><td>F6b.</td><td>Conflict with or repeated criticism of staff</td></tr><tr><td>F6c.</td><td>Staff report persistent frustration in dealing with person</td></tr><tr><td>F6d.</td><td>Family or close friends report feeling overwhelmed by person’s illness</td></tr></tbody></table><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size table</div><figcaption><p><strong>Table 5</strong> VC-IOE items adapted for Mon-chan [31]</p></figcaption><table><thead><tr><th>Emotion</th><th>Positive</th><th>Smiling, laughing, singing, responding to Mon-chan</th></tr></thead><tbody><tr><td>(Facial emotional response)</td><td>Negative</td><td>Physical aggression, yelling, cursing, drawing eyebrows together. Clenching teeth, pursing lips, narrowing eyes. Voice shaking, shrieking, repetitive calling out, line between eyebrows. Lines across forehead, tight facial muscles. Crying, frowning, eyes drooped, moaning, sighing, eyes/head turned down</td></tr><tr><td></td><td>Neutral/missing</td><td>Relaxed or no sign of discrete facial expression</td></tr><tr><td>Verbal engagement</td><td>Positive</td><td>General talking. Participating and maintaining conversation, verbally responding to statements/questions. Expressing positive feelings towards Mon-chan</td></tr><tr><td></td><td>Negative</td><td>Verbalizes the desire to leave. Refuses to participate in the activity by verbalizing “no”, “stop”, etc. Makes repetitive generalized somatic complaints. Cursing and swearing</td></tr><tr><td></td><td>Neutral/missing</td><td>Not participating in or maintaining conversation. Not responding or talking to the facilitator when prompted</td></tr><tr><td>Auditory engagement</td><td>Positive</td><td>Participating and maintaining conversation</td></tr><tr><td></td><td>Negative</td><td>Hard of hearing, no response</td></tr><tr><td>Visual engagement</td><td>Positive</td><td>Appears alert, and maintaining eye contact with facilitator or others. Eyes following facilitator or others</td></tr><tr><td></td><td>Negative</td><td>Appears inattentive, blank stares into space, no eye contact.</td></tr><tr><td>Behavioral engagement</td><td>Positive</td><td>Touching or attempting to touch Mon-chan. Stroking, petting, nuzzling</td></tr><tr><td></td><td>Negative</td><td>Hitting, shaking and handling Mon-chan inappropriately. Pushing Mon-chan away</td></tr><tr><td></td><td>Missing</td><td>No touching; no physical contact with Mon-chan or not handling Mon-chan</td></tr><tr><td>Collective engagement</td><td>Yes</td><td>Encouraging others to interact with Mon-chan. Introducing Mon-chan to the facilitator. Using Mon-chan as a communication channel to interact and talk with others</td></tr><tr><td></td><td>No</td><td>No sign of collective engagement</td></tr><tr><td>Evidence of agitation</td><td>Yes (verbal, vocal, motor activity)</td><td>Restlessness, repeated/agitated movement (frequent non-purposeful movement), moving in chair, picking at and fiddling with clothes; repetitive rubbing of own limbs or torso; appears anxious, abusive or aggressive toward self or others</td></tr><tr><td></td><td>No</td><td>No sign of agitation as described above</td></tr><tr><td>Need of facilitator’s involvement</td><td>No</td><td>Only at the beginning</td></tr><tr><td></td><td>Yes</td><td>Prompting 2–3 times</td></tr><tr><td></td><td></td><td>Prompting several times</td></tr></tbody></table><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size table</div><p>The other method, VC-IOE was devised by Jones et al. [32] for observing short-term emotional changes when older persons use the pet-type robot PARO. The list of observation items include six categories “Emotional engagement”, “Verbal engagement”, “Visual engagement”, “Behavioral engagement”, “Collective engagement” and “Agitation”). This coding framework was adapted and translated into Japanese [ [32], p.380], and used for the current study (Table 5). The participants were asked to spend time with Mon-chan individually during their recreation, and their 3-min interactions were video-taped with their permission (Fig. 4). A pair of care professionals observed the interactions and took notes. This was carried out partly to test individual responses to Mon-chan, which is designed to be both a non-verbal (cuddly toy) and a verbal robot. Mon-chan in both modes was examined. Three researchers (two care professionals and one external researcher) subsequently analyzed the recorded videos, using the VC-IOE method (Japanese version). The disagreements between coders were adjusted after a few pilot recordings and discussions. The results are shown in Sect. 3.3.</p><p><img src=/img/soft-robot_fig4.jpg alt="Verbal exchanges with Mon-chan during recreation"></p><figcaption><p><strong>Fig. 4</strong>
figure4
Verbal exchanges with Mon-chan during recreation</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><h3 id=changes-of-qol-assessed-by-interrai>Changes of QoL Assessed by interRAI
<a class=anchor href=#changes-of-qol-assessed-by-interrai>#</a></h3><p>The overall interRAI scores for the two categories were 11.9±9.7 before the introduction of Mon-chan. Four weeks later, the scores changed to 10.2±7.9 10.2 ±7.9, which was statistically significant (<em>p</em> &lt; 0.01). At the individual level, 57 percent of participants’ scores improved while 20 percent remained the same and 23 percent worsened. In particular, E1 “Indicators of possible depressed, anxious or sad mood” showed a marked improvement (<em>p</em> &lt; 0.005), while E3 “behavior and mood” showed some improvements (<em>p</em> = 0.08). Looking at each item, E1b (persistent anger with self or others, <em>p</em> = 0.03), E1d (repetitive health complaints, <em>p</em> = 0.02), E1e (repetitive anxious complaints/concerns (non-health related), <em>p</em> = 0.02), E1h (recurrent statements that something terrible is about to happen, <em>p</em> = 0.03), these individual items for category E also indicated statistically significant improvement (<em>p</em> &lt; 0.05). Furthermore, positive improvements were also found in E3b (Verbal abuse, <em>p</em> = 0.08), E3e (Inappropriate public sexual behavior or public disrobing, <em>p</em> = 0.08) and E3g (Absconding or at risk of absconding, <em>p</em> = 0.08). On the contrary, F4 (Length of time alone during the day, <em>p</em> = 0.39), F5 (Willingness to initiate or participate, <em>p</em> = 0.4) and F6 (Instability of interpersonal relationship was statistically significant, <em>p</em> = 0.33) did not show any change. Overall the psychosocial burden was reduced, and it can be argued that Mon-chan had a positive effect on the quality of life of the participants.</p><h3 id=short-term-emotional-changes-captured-by-vc-ioe>Short-Term Emotional Changes Captured by VC-IOE
<a class=anchor href=#short-term-emotional-changes-captured-by-vc-ioe>#</a></h3><p>For this study, each item was given a score of − 2 (worse), − 1 (bad), 0 (no change), + 1 (good), + 2 (improvement) by the coder, observing the three-minute clip. Although it was a short-term change, a positive stimulating effect was observed for the categories (“Emotional engagement”, “Verbal engagement”, “Visual engagement”, “Behavioral engagement”). Figure 5 shows the comparison of total scores in each category between verbal and non-verbal Mon-chan. The results demonstrate particularly positive engagement with the (non-verbal) Mon-chan doll compared to that with the verbal Mon-chan robot. However there was no statistically significant difference. The combined counts of positive scores (“good” and “improvement”) accounted for more than half (55.2%) for non-verbal Mon-chan, and 42.0% for verbal Mon-chan (Fig. 5). We further investigated the data for non-verbal Mon-chan’s effect on the participants with dementia.</p><p>Focusing on non-verbal responses, we used the Mini-Mental State Exam (MMSE) scores to measure the level of dementia, as it was deemed pertinent to examine whether any patterns were detected between those scores and the results from the VC-IOE method. The MMSE is a 30-point test used to measure the degree of cognitive ability. The test includes orientation to time and place, short-term memory, attention and ability to solve problems, language and comprehension and motor skills, and the greater the scores are, the greater the ability is [31]. A mildly positive linear regression was observed (Fig. 6), suggesting that there is a possible positive pattern depending on the level of dementia. People with dementia can potentially make positive use of the Mon-chan doll. As previous studies show, even soft plush toys without communicative functions can have therapeutic impact on older people with impaired cognitive ability, with the assistance of carers.</p><p><img src=/img/soft-robot_fig5.png alt="Verbal and non-verbal Mon-chan compared"></p><figcaption><p><strong>Fig. 5</strong>
figure5
Verbal and non-verbal Mon-chan compared</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><p><img src=/img/soft-robot_fig6.png alt="Relationship between non-verbal Mon-chan’s effect and the level of dementia"></p><figcaption><p><strong>Fig. 6</strong>
figure6
Relationship between non-verbal Mon-chan’s effect and the level of dementia (X axis: MMSE scores; Y axis: individual scores using the VC-IOE method)</p></figcaption><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Full size image</div><h2 id=discussion>Discussion
<a class=anchor href=#discussion>#</a></h2><p>The research team aimed to develop an SAR which is user-friendly, is appealing, and contributes to better and safer care delivery. The aim was to overcome formerly observed weaknesses of SARs and draw on the views of users (residents and care professionals working on site) in the nursing home. The result was the production of Mon-chan, which was designed, developed, introduced and evaluated on site. User-centered design still remains relatively uncommon in the domain of robotics design and development for care of older people, particularly for SARs in Japan [6,7,8]. This can be attributed to several factors, including the difficulty of having a regular dialogue or forum where developers, care recipients and care professionals can meet and discuss their needs and preferences. Moreover, there has been a scarcity of research evidence to support the arguments that these SARs can improve quality of life for older adults. Because of this, stakeholders and users can be skeptical and take a cautious approach [33]. In the last few years, more research results are being published [4, 17,18,19,20], and this situation is likely to improve. There are also some studies highlighting (potential) users’ perceptions and attitudes towards care robots [34, 35]. Ethical issues have also been examined and considered by researchers and bodies such as the IEEE [36,37,38]. Furthermore, SARs can only be utilized fully when care recipients and care professionals find them both user-friendly and useful. The application of ATs in this area needs careful consideration of users’ needs and workforce development implications. Successful implementation requires multi-level thinking (from user experience and organizational processes to policy and industry context) and the understanding that technology-supported work is cooperative and embedded in organizational routines [39].</p><p>For this study, we also assessed the changes in interRAI scores over the 4-week period when Mon-chan was used. The results indicated that mood and behavior of the participants improved significantly, while psychosocial aspects remained stable. Simultaneously, using the VC-IOE observation framework, the findings showed positive engagement of the participants, irrespective of the difference in type (verbal vs. non-verbal). Non-verbal use of Mon-chan exceeded the expectations of this study, generating very positive engagement in emotional, verbal, visual and behavioral aspects (Fig. 5). While the mechanism through which the technology-driven system improved residents’ quality of life requires future study, it could be argued that the reflection of their voices in the design process of Mon-chan contributed to their engagement. On the other hand, the positive impact of Mon-chan with communicative functions was not clear, considering the relatively lower positive scores than those for non-verbal Mon-chan (Fig. 4). Although the improved sound quality of Mon-chan’s verbal function was noted, the interactions between care recipients and verbal Mon-chan did not yield positive behavioral or collective engagement. Therefore, as indicated by the previous study [40], the impact of verbal SARs and non-verbal plush toys on older adults with dementia is inconclusive. Further research is needed to examine the relationship and improve the communication functionalities. It is also worth investigating how we can accurately measure the impact of these SARs and ATs on the quality of life of older people. There are a variety of assessment tools such as the WHO’s International Classification of Functioning, Disability and Health (ICF), Dementia Behavior Disturbance Scale-13 (DBD-13), Cohen-Manfield Agitation Inventory (CMAI), Neuropsychiatric Inventory with Caregiver Distress Scale (NPI-D), with the interRAI being merely one of them. For our study, interRAI was deemed highly effective and accurate in capturing the changes in residents’ mood and behavior, though this merits further examination.</p><p>The limitations of this study include the small sample size and the absence of a longitudinal study design to examine the impact of a longer period of SAR use on care recipients, care professionals and the nursing home. The analysis of contributing factors such as organizational context, physical environment, and the impact of unanticipated disruptions to daily care routines (e.g. Covid19 pandemic) is also worth considering, although it is beyond the scope of this paper. Nonetheless, the study demonstrated the significance of care professionals’ involvement in the design and development of an original soft social robot as a way of translating the voice of older adults with impaired cognitive and sensory ability. By assessing the impact, and despite some inconclusive results, the production loop of SARs was closed, which fulfilled the principle of gemba. Whether care professionals’ involvement in SARs design, production and evaluation can lead to greater job satisfaction and a better work environment also needs further research. However, this study is well-aligned with the progress towards the RRI framework [9], with greater public and patient involvement. Future research into and development of care robots need to examine the connection between process and outcomes.</p><h2 id=conclusions>Conclusions
<a class=anchor href=#conclusions>#</a></h2><p>This study outlined the user-centered design and evaluation of a socially assistive robot within the context of a nursing home in Japan. The collaborative developmental process among different stakeholders-manufacturers, care professionals, care recipients and researchers, improved quality of life among residents. The original SAR “Mon-chan” was connected to existing ATs (monitoring camera, nurse call, and biomedical sensor), which contributed to safety and enhanced quality of care. This safety function, in addition to the socially assistive one, provides another layer of security for care recipients and care professionals. As the new coronavirus infectious disease has highlighted, there is now a new focus on the introduction of telemedicine, and applications of remote monitoring and care delivery models as countermeasures for the spread of the virus and the protection of older people in nursing care facilities. The importance of user-oriented design and development of robotics-aided care for the improvement of a care system will continue to be highlighted in the future.</p><h2 id=references>References
<a class=anchor href=#references>#</a></h2><ol><li><p>Taylor ME, Close JCT (2018) Dementia. <em>Handb Clin Neurol</em> 159:303–321
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>WHO (2015) <em>World report on ageing and health</em>. World Health Organization, Geneva, Switzerland</p></li><li><p>Broadbent E, Stafford R, MacDonald B (2009) Acceptance of healthcare robots for the older population: review and future directions. <em>Int J of Soc Robotics</em> 1:319–330
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Obayashi K, Kodate N, Masuyama S (2018) Socially assistive robots and their potential in enhancing older people’s activity and social participation. <em>J Am Med Dir Assoc</em> 19(5):462–463. <a href=https://doi.org/10.1093/geront/gnx180>https://doi.org/10.1093/geront/gnx180</a></p></li><li><p>Block A, Kuchenbecker K (2019) Softness, warmth, and responsiveness improve robot hugs. <em>Int J of Soc Robotics</em> 11:49–64
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Bradwell HL, Edwards KJ, Winnington R, Thill S, Jones RB (2019) Companion robots for older people: importance of user-centred design demonstrated through observations and focus groups comparing preferences of older people and roboticists in South West England. <em>BMJ Open</em> 9:303–321. <a href=https://doi.org/10.1136/bmjopen-2019-032468>https://doi.org/10.1136/bmjopen-2019-032468</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>White Paper on people with disabilities, <em>Heisei</em> 27, Cabinet Office of Japan (2015). <a href=https://www8.cao.go.jp/shougai/whitepaper/h27hakusho/zenbun/h1_06_01_06.html>https://www8.cao.go.jp/shougai/whitepaper/h27hakusho/zenbun/h1_06_01_06.html</a>. Accessed 30 April 2021</p></li><li><p>Koutentakis D, Pilozzi A, Huang X (2020) Designing socially assistive robots for Alzheimer’s disease and related dementia patients and their caregivers: where we are and where we are headed. <em>Healthcare</em>. <a href=https://doi.org/10.3390/healthcare8020073>https://doi.org/10.3390/healthcare8020073</a></p></li><li><p>Stahl B, Coeckelbergh M (2016) Ethics of healthcare robotics: towards responsible research and innovation. <em>Robot Autonom Syst</em> 86(12):152–161
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Bourgault A, Upvall M, Graham A (2018) Using Gemba boards to facilitate evidence-based practice in critical care. <em>Crit Care Nurse</em> 38(3):e1–e7
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Liebengood SM, Cooper M, Nagy P (2013) Going to the Gemba: identifying opportunities for improvement in radiology. <em>J Am Coll Radiol</em> 10(12):977–979
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Pilotto A, D’Onofrio G, Benelli E, Zanesco A, Cabello A, Margelí MC, Wanche-Politis S, Seferis K, Sancarlo D, Kilias D (2011) Information and communication technology systems to improve quality of life and safety of Alzheimer’s disease patients: a multicenter international survey. <em>J Alzheimers Dis</em> 23:131–141. <a href=https://doi.org/10.3233/JAD-2010-101164>https://doi.org/10.3233/JAD-2010-101164</a></p></li><li><p>Takayanagi K, Kirita T, Shibata T (2014) Comparison of verbal and emotional responses of elderly people with mild/moderate dementia and those with severe dementia in responses to seal robot, PARO. <em>Front Aging Neurosci</em> 6:257
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Bemelmans R, Gelderblom GJ, Jonker P, Witte LD (2015) Effectiveness of robot PARO in intramural psychogeriatric care: a multicenter quasi-experimental study. <em>J Am Med Dir Assoc</em> 16:946–950. <a href=https://doi.org/10.1016/j.jamda.2015.05.007>https://doi.org/10.1016/j.jamda.2015.05.007</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Moyle W, Jones CJ, Murfield LukmanThalib JE, Beattie ERA, Shum DKH, O’Dwyer ST, Mervin MC, Draper BM (2017) Use of a robotic seal as a therapeutic tool to improve dementia symptoms: a cluster-randomized controlled trial. <em>J Am Med Dir Assoc</em> 18(9):766–773. <a href=https://doi.org/10.1016/j.jamda.2017.03.018>https://doi.org/10.1016/j.jamda.2017.03.018</a></p></li><li><p>Nuovo AD, Broz F, Wang N, Belpaeme T, Cangelosi A, Jones R, Esposito R, Cavallo F, Dario P (2017) The multi-modal interface of robot-era multi-robot services tailored for the elderly. <em>Int J Soc Robotics</em> 11:109–126. <a href=https://doi.org/10.1007/s11370-017-0237-6>https://doi.org/10.1007/s11370-017-0237-6</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Wilson JR, Lee NY, Saechao A, Tickle-Degnen L, Scheutz M (2018) Supporting human autonomy in a robot-assisted medication sorting task. <em>Int J Soc Robotics</em> 10:621–641. <a href=https://doi.org/10.1007/s12369-017-0456-1>https://doi.org/10.1007/s12369-017-0456-1</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Pu L, Moyle W, Jones C (2019) The multi-modal interface of robot-era multi-robot services tailored for the elderly. <em>J Clin Nurs</em> 29:437–446. <a href=https://doi.org/10.1111/jocn.15104>https://doi.org/10.1111/jocn.15104</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Moyle W, Bramble M, Jones CJ, Murfield J (2019) “She had a smile on her face as wide as the great Australian bite”: a qualitative examination of family perceptions of a therapeutic robot and a plush toy. <em>Gerontologist</em> 59(1):177–185. <a href=https://doi.org/10.1093/geront/gnx180>https://doi.org/10.1093/geront/gnx180</a></p></li><li><p>Obayashi K, Kodate N, Masuyama S (2018) Enhancing older people’s activity and participation with socially assistive robots: a multicentre quasi-experimental study using the ICF framework. <em>Adv Robot</em> 3(22):1207–1216</p></li><li><p>Obayashi K, Kodate N, Masuyama S (2020) Can connected technologies improve sleep quality and safety of older adults and care-givers? An evaluation study of sleep monitors and communicative robots at a residential care home in Japan. <em>Technol Soc</em>. <a href=https://doi.org/10.1016/j.techsoc.2020.101318>https://doi.org/10.1016/j.techsoc.2020.101318</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Obayashi K, Kodate N, Masuyama S (2020) Measuring the impact of age, gender and dementia on communication-robot interventions in residential care homes. <em>Geriatr Gerontol Int</em> 24(4):373–378. <a href=https://doi.org/10.1111/ggi.13890>https://doi.org/10.1111/ggi.13890</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Masuyama S, Obayashi K, Ogata T, Kondo H, Okamoto Y, Ishii Y (2017) Measuring impacts of introducing communicative robots with infrared radiation monitoring system on workload of night shifts in nursing care facilities. <em>Age Ageing</em> 46:iii13–iii59
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Whelan S, Murphy K, Barrett E, Krusche C, Santorelli A, Casey D (2018) Factors affecting the acceptability of social robots by older adults including people with dementia or cognitive impairment: a literature review. <em>Int J of Soc Robot</em> 10:643–668. <a href=https://doi.org/10.1007/s12369-018-0471-x>https://doi.org/10.1007/s12369-018-0471-x</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Hung L, Liu C, Woldum E, Au-Yeung A, Berndt A, Wallsworth C, Horne N, Gregorio M, Mann J, Chaudhury H (2019) The benefits of and barriers to using a social robot PARO in care settings: a scoping review. <em>BMC Geriatr</em>. <a href=https://doi.org/10.1186/s12877-019-1244-6>https://doi.org/10.1186/s12877-019-1244-6</a>.
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Accessed 26 April 2021</div></p></li><li><p>Technical Committee for Soft Robotics, IEEE Robotics and Automation Society. <a href=https://www.ieee-ras.org/soft-robotics>https://www.ieee-ras.org/soft-robotics</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Accessed 26 April 2021</div></p></li><li><p>Carpenter I, Hirdes JP (2013) A good life in old age? Monitoring and improving quality in long-term care. OECD/European Commission, Ch. Using interRAI assessment systems to measure and maintain quality of long-term care, pp 93–127</p></li><li><p>Morris JN, Fries BE, Frijters D, Hirdes JP, Steel RK (2013) interRAI home care quality indicators. <em>BMC Geriatr</em>. <a href=https://doi.org/10.1186/1471-2318-13-127>https://doi.org/10.1186/1471-2318-13-127</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Hirdes JP, Everdingen CV, Ferris J, Franco-Martin M, Fries BE, Heikkilä J, Hirdes J, Hoffman R, James ML, Martin L, Perlman CM, Rabinowitz T, Stewart SL, van Audenhove C (2019) The interRAI suite of mental health assessment instruments: an integrated system for the continuum of care. <em>Front Psychiatry</em>. <a href=https://doi.org/10.3389/fpsyt.2019.00926>https://doi.org/10.3389/fpsyt.2019.00926</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Ikegami N, Ishibashi T, Hirdes TT (2017) interRAI hoshiki gaido bukku: kea puran sakusei/shitsu no kanri/kango deno katsuyo (interrai method guidebook: care planning, quality control and utilization in nursing, in Japanese). <a href=https://doi.org/10.3389/fpsyt.2019.00926>https://doi.org/10.3389/fpsyt.2019.00926</a></p></li><li><p>Pangman V, Sloan J, Guse L (2000) An examination of psychometric properties of the mini-mental status examination and the standardized mini-mental status examination: implications for clinical practice. <em>Appl Nurs Res</em> 13(4):209–213
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Jones C, Sung B, Moyle W (2015) Assessing engagement in people with dementia: a new approach to assessment using video analysis. <em>Arch Psychiatr Nurs</em> 29(6):5–24. <a href=https://doi.org/10.1016/j.apnu.2015.06.019>https://doi.org/10.1016/j.apnu.2015.06.019</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Wright J (2019) Robots vs migrants? Reconfiguring the future of Japanese institutional eldercare. <em>Crit Asian Stud</em> 51(3):331–354. <a href=https://doi.org/10.1080/14672715.2019.1612765>https://doi.org/10.1080/14672715.2019.1612765</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Vandemeulebroucke T, de Casterlé BD, Gastmans C (2018) The use of care robots in aged care: a systematic review of argument-based ethics literature. <em>Arch Gerontol Geriatr</em> 74:15–25. <a href=https://doi.org/10.1016/j.archger.2017.08.01>https://doi.org/10.1016/j.archger.2017.08.01</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Suwa S, Tsujimura M, Kodate N, Donnelly S, Kitinoja H, Hallila J, Toivonen M, Ide H, Bergman-Kärpijoki C, Takahashi E, Ishimaru M, Shimamura A, Yu W (2020) Exploring perceptions towards home-care robots for older people in Finland, Ireland, and Japan: a comparative questionnaire study. <em>Arch Gerontol Geriatr</em> 91:104178
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Bennett B, McDonald F, Beattie E, Carney T, Freckelton I, White B, Willmott L (2017) Assistive technologies for people with dementia: ethical considerations. <em>Bull World Health Organ</em> 95:749–755. <a href=https://doi.org/10.2471/BLT.16.187484>https://doi.org/10.2471/BLT.16.187484</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p>Anderson M, Anderson SL, Berenz V (2019) A value-driven eldercare robot: virtual and physical instantiations of a case-supported principle-based behavior paradigm. <em>Proc IEEE</em> 107:526–540. <a href=https://doi.org/10.1109/JPROC.2018.2840045>https://doi.org/10.1109/JPROC.2018.2840045</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article
Google Scholar</div></p></li><li><p><em>Ethically aligned design: a vision for prioritizing human well-being with autonomous and intelligent systems</em>, The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (2019). <a href=https://standards.ieee.org/content/ieee-standards/en/industry-connections/ec/autonomous-systems.html>https://standards.ieee.org/content/ieee-standards/en/industry-connections/ec/autonomous-systems.html</a></p></li><li><p>Greenhalgh T, Shaw S, Wherton J, Hughes G, Lynch J, A’Court C, Hinder S, Fahy N, Byrne E, Finlayson A, Sorell T, Procter R, Stones R (2016) SCALS: a fourth-generation study of assisted living technologies in their organisational, social, political and policy context. <em>BMJ Open</em>. <a href=https://doi.org/10.1136/bmjopen-2015-010208>https://doi.org/10.1136/bmjopen-2015-010208</a></p></li><li><p>Rantan T, Lehto P, Vuorinen P, Coco K (2018) The adoption of care robots in home care—a survey on the attitudes of Finnish home care personnel. <em>J Clin Nurs</em> 27(9–10):1846–1859. <a href=https://doi.org/10.1111/jocn.14355>https://doi.org/10.1111/jocn.14355</a>
<link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Article</br>Google Scholar<p>Download references</p></div></p></li></ol><h2 id=acknowledgements>Acknowledgements
<a class=anchor href=#acknowledgements>#</a></h2><p>This study was in part financially supported by The Japan Keirin Autorace Foundation and The Toyota Foundation (D18-ST-0005). The authors wish to thank all the participants, funding bodies, A.I.Viewlife Co. Ltd., NTT Data Corporation, Trendmaster Ltd. and Yukai Engineering Inc., and staff members who provided help. We would particularly like to thank Hiromasa Kondo, Yoshimi Okamoto, Yoko Ishii, Takahiro Nonoda and Mark Linne.</p><h2 id=author-information>Author information
<a class=anchor href=#author-information>#</a></h2><h3 id=affiliations>Affiliations
<a class=anchor href=#affiliations>#</a></h3><p>Faculty of Healthcare Management, Nihon Fukushi University, Mihama, Japan
Kazuko Obayashi</p><p>Social Welfare Corporation Tokyo Seishin-kai, Nishitokyo, Japan
Kazuko Obayashi</p><p>Universal Accessibility and Ageing Research Centre, Nishitokyo, Japan
Kazuko Obayashi, Naonori Kodate & Shigeru Masuyama</p><p>School of Social Policy, Social Work and Social Justice, University College Dublin, Hanna Sheehy Skeffington Building, Belfield, Dublin 4, D04 N9Y1, Ireland
Naonori Kodate</p><p>Institute for Future Initiatives, University of Tokyo, Tokyo, Japan
Naonori Kodate</p><p>Public Policy Research Center, Hokkaido University, Sapporo, Japan
Naonori Kodate</p><p>La Fondation France-Japon, L’ École des hautes études en sciences sociales, Paris, France
Naonori Kodate</p><p>Traveler’s Medical Center, Tokyo Medical University, Tokyo, Japan
Shigeru Masuyama</p><h3 id=corresponding-author>Corresponding author
<a class=anchor href=#corresponding-author>#</a></h3><p>Correspondence to Naonori Kodate.</p><h2 id=ethics-declarations>Ethics declarations
<a class=anchor href=#ethics-declarations>#</a></h2><h3 id=conflict-of-interest>Conflict of interest
<a class=anchor href=#conflict-of-interest>#</a></h3><p>The authors declare that they have no conflict of interest.</p><h2 id=additional-information>Additional information
<a class=anchor href=#additional-information>#</a></h2><h3 id=publishers-note>Publisher&rsquo;s Note
<a class=anchor href=#publishers-note>#</a></h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p><h2 id=rights-and-permissions>Rights and permissions
<a class=anchor href=#rights-and-permissions>#</a></h2><p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href=http://creativecommons.org/licenses/by/4.0/>http://creativecommons.org/licenses/by/4.0/</a>.</p><h2 id=reprints-and-permissions>Reprints and Permissions
<a class=anchor href=#reprints-and-permissions>#</a></h2><h3 id=about-this-article>About this article
<a class=anchor href=#about-this-article>#</a></h3><p>Verify currency and authenticity via CrossMark</p><h3 id=cite-this-article>Cite this article
<a class=anchor href=#cite-this-article>#</a></h3><p>Obayashi, K., Kodate, N. & Masuyama, S. Assessing the Impact of an Original Soft Communicative Robot in a Nursing Home in Japan: Will Softness or Conversations Bring more Smiles to Older People?. Int J of Soc Robotics (2021). <a href=https://doi.org/10.1007/s12369-021-00815-4>https://doi.org/10.1007/s12369-021-00815-4</a></p><p>Download citation</p><p>Accepted
19 July 2021</p><p>Published
07 August 2021</p><p>DOI
<a href=https://doi.org/10.1007/s12369-021-00815-4>https://doi.org/10.1007/s12369-021-00815-4</a></p><h3 id=share-this-article>Share this article
<a class=anchor href=#share-this-article>#</a></h3><p>Anyone you share the following link with will be able to read this content:</p><h3 id=get-shareable-link>Get shareable link
<a class=anchor href=#get-shareable-link>#</a></h3><p>Provided by the Springer Nature SharedIt content-sharing initiative</p><h2 id=keywords>Keywords
<a class=anchor href=#keywords>#</a></h2><p>Socially assistive robot
Eldercare
Communication
User-centered design
Human–robot interaction
Technology assessment</p><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Download PDF</br>Sections</br>Figures</br>References</br>Abstract</br>Introduction</br>Research Settings, Robot Design and Development Process</br>Evaluation of Verbal and Non-verbal Mon-chan</br>Discussion</br>Conclusions</br>References</br>Acknowledgements</br>Author information</br>Ethics declarations</br>Additional information</br>Rights and permissions</br>About this article</div><h2 id=advertisement>Advertisement
<a class=anchor href=#advertisement>#</a></h2><p>Over 10 million scientific documents at your fingertips</p><link href="https://fonts.googleapis.com/css?family=Rubik+Iso" rel=stylesheet type=text/css><div style="font-family:rubik iso;font-size:9pt;font-style:normal;color:normal;font-weight:400">Switch Edition</br>Academic Edition Corporate Edition
Home Impressum Legal information Privacy statement California Privacy Statement How we use cookies Manage cookies/Do not sell my data Accessibility Contact us<p>Not logged in - 00.000.000.000</p>Not affiliated
Springer Nature</div><p>© 2021 Springer Nature Switzerland AG. Part of Springer Nature.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Faculty of Healthcare Management, Nihon Fukushi University, Mihama, Japan&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Social Welfare Corporation Tokyo Seishin-kai, Nishitokyo, Japan&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Universal Accessibility and Ageing Research Centre, Nishitokyo, Japan&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>School of Social Policy, Social Work and Social Justice, University College Dublin, Hanna Sheehy Skeffington Building, Belfield, Dublin 4 D04 N9Y1, Ireland&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Institute for Future Initiatives, University of Tokyo, Tokyo,&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>Public Policy Research Center, Hokkaido University, Sapporo, Japan&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>La Fondation France-Japon, L’ École des hautes études en sciences sociales, Paris, France&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p>Traveler’s Medical Center, Tokyo Medical University, Tokyo, Japan&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#research-settings-robot-design-and-development-process>Research Settings, Robot Design and Development Process</a><ul><li><a href=#settings-and-participants>Settings and Participants</a></li><li><a href=#user-centered-design-and-development-in-a-nursing-home>User-Centered Design and Development in a Nursing Home</a></li><li><a href=#development-of-conversation-scenarios>Development of Conversation Scenarios</a></li></ul></li><li><a href=#evaluation-of-verbal-and-non-verbal-mon-chan>Evaluation of Verbal and Non-verbal Mon-chan</a><ul><li><a href=#evaluation-methods-and-procedures>Evaluation Methods and Procedures</a></li><li><a href=#changes-of-qol-assessed-by-interrai>Changes of QoL Assessed by interRAI</a></li><li><a href=#short-term-emotional-changes-captured-by-vc-ioe>Short-Term Emotional Changes Captured by VC-IOE</a></li></ul></li><li><a href=#discussion>Discussion</a></li><li><a href=#conclusions>Conclusions</a></li><li><a href=#references>References</a></li><li><a href=#acknowledgements>Acknowledgements</a></li><li><a href=#author-information>Author information</a><ul><li><a href=#affiliations>Affiliations</a></li><li><a href=#corresponding-author>Corresponding author</a></li></ul></li><li><a href=#ethics-declarations>Ethics declarations</a><ul><li><a href=#conflict-of-interest>Conflict of interest</a></li></ul></li><li><a href=#additional-information>Additional information</a><ul><li><a href=#publishers-note>Publisher&rsquo;s Note</a></li></ul></li><li><a href=#rights-and-permissions>Rights and permissions</a></li><li><a href=#reprints-and-permissions>Reprints and Permissions</a><ul><li><a href=#about-this-article>About this article</a></li><li><a href=#cite-this-article>Cite this article</a></li><li><a href=#share-this-article>Share this article</a></li><li><a href=#get-shareable-link>Get shareable link</a></li></ul></li><li><a href=#keywords>Keywords</a></li><li><a href=#advertisement>Advertisement</a></li></ul></nav></div></aside></main></body></html>